{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07234537",
   "metadata": {},
   "source": [
    "# In this lecture We will Cover\n",
    "     1.PySpark Dataframe\n",
    "     2.Reading The Dataset\n",
    "     3.Checking the Datatypes of the Column(Schema)\n",
    "     4.Selecting Columns And Indexing\n",
    "     5.Check Describe option similar to Pandas\n",
    "     6.Adding Columns\n",
    "     7.Dropping columns\n",
    "     8.Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f62ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    " from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a43c4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81797ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-QVPOJIS:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1680e179af0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b69232cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the dataset\n",
    "df_pyspark=spark.read.option('header','true').csv('indian movies.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "431527ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Movie Name: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Timing(min): string (nullable = true)\n",
      " |-- Rating(10): string (nullable = true)\n",
      " |-- Votes: string (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdd100c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+-----------+----------+------+--------------------+--------+\n",
      "|       ID|          Movie Name|      Year|Timing(min)|Rating(10)| Votes|               Genre|Language|\n",
      "+---------+--------------------+----------+-----------+----------+------+--------------------+--------+\n",
      "|tt0398974|         Dr. Shaitan|      1960|          -|         -|     -|                   -|   hindi|\n",
      "|tt1702558|          Nadir Khan|      1968|          -|         -|     -|                   -|    urdu|\n",
      "|tt0493437|Apna Sapna Money ...|      2006|    134 min|       5.3| 1,892|Comedy, Musical, ...|   hindi|\n",
      "|tt0273405|      Aag Aur Sholay|      1987|          -|       2.2|    20|                   -|    urdu|\n",
      "|tt0049595|             Parivar|      1956|          -|       7.4|    21|Comedy, Drama, Fa...|   hindi|\n",
      "|tt2930026|Humraah: The Traitor|      2008|          -|         -|     -|Thriller            |   hindi|\n",
      "|tt6597160|Jacqueline I Am C...|      2019|    112 min|       7.9|    16|   Drama            |   hindi|\n",
      "|tt0829459|      A Mighty Heart|      2007|    108 min|       6.6|26,885|Biography, Drama,...|    urdu|\n",
      "|tt0154875|       Midnight Mail|      1939|          -|         -|     -|  Action            |   hindi|\n",
      "|tt0364628|          Raktalekha|      1992|    175 min|       6.3|    12|   Drama            | bengali|\n",
      "|tt0364733|   Veedevadandi Babu|      1997|    138 min|       5.6|   218|  Comedy            |  telugu|\n",
      "|tt8272296|   A Mayalu Timi Lai|2018 Video|          -|         -|     -|Short, Music     ...|  nepali|\n",
      "|tt5684550|   Da Tang Xuan Zang|      2016|     90 min|       6.2|   379|Biography, Histor...|sanskrit|\n",
      "|tt0250733|            Sikandar|      1976|          -|         -|     -|                   -|   hindi|\n",
      "|tt1407272|         Pehla Qadam|      1958|          -|         -|     -|                   -|    urdu|\n",
      "|tt0318983|Amman Koil Kizhak...|      1986|    141 min|       6.9|    63|   Drama            |   tamil|\n",
      "|tt3148392|              Shatru|      2013|          -|       4.5|    11|Action, Thriller ...| kannada|\n",
      "|tt7836398|Kamal Khatri Feat...|2017 Video|      5 min|         -|     -|Short, Music     ...|  nepali|\n",
      "|tt0376353|   Zinda Jala Doonga|      1988|          -|         -|     -|  Action            |   hindi|\n",
      "|tt2302945|             Tukaram|      2012|    156 min|       7.3|   231|Biography, Drama,...| marathi|\n",
      "+---------+--------------------+----------+-----------+----------+------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('indian movies.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4f58a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Movie Name: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Timing(min): string (nullable = true)\n",
      " |-- Rating(10): string (nullable = true)\n",
      " |-- Votes: string (nullable = true)\n",
      " |-- Genre: string (nullable = true)\n",
      " |-- Language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e77ce559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|month|spend|\n",
      "+-----+-----+\n",
      "|  jan|10000|\n",
      "|  feb|10000|\n",
      "|  mar|10000|\n",
      "|  apr|10000|\n",
      "|  may|10000|\n",
      "|  jun|10000|\n",
      "|  jul|10000|\n",
      "|  aug|10000|\n",
      "|  sep|10000|\n",
      "|  oct|10000|\n",
      "|  nov|10000|\n",
      "|  dec|10000|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# by default all the attributes see as string\n",
    "df_pyspark=spark.read.csv('Book1.csv',header=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a27ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: string (nullable = true)\n",
      " |-- spend: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d57ba645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|month|spend|\n",
      "+-----+-----+\n",
      "|  jan|10000|\n",
      "|  feb|10000|\n",
      "|  mar|10000|\n",
      "|  apr|10000|\n",
      "|  may|10000|\n",
      "|  jun|10000|\n",
      "|  jul|10000|\n",
      "|  aug|10000|\n",
      "|  sep|10000|\n",
      "|  oct|10000|\n",
      "|  nov|10000|\n",
      "|  dec|10000|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to solve this we use inferSchema=True\n",
    "df_pyspark=spark.read.csv('Book1.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46d3d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: string (nullable = true)\n",
      " |-- spend: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a0edc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c8559a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(month='jan', spend=10000),\n",
       " Row(month='feb', spend=10000),\n",
       " Row(month='mar', spend=10000)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d8e9fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|month|spend|\n",
      "+-----+-----+\n",
      "|  jan|10000|\n",
      "|  feb|10000|\n",
      "|  mar|10000|\n",
      "|  apr|10000|\n",
      "|  may|10000|\n",
      "|  jun|10000|\n",
      "|  jul|10000|\n",
      "|  aug|10000|\n",
      "|  sep|10000|\n",
      "|  oct|10000|\n",
      "|  nov|10000|\n",
      "|  dec|10000|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbe473db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|month|\n",
      "+-----+\n",
      "|  jan|\n",
      "|  feb|\n",
      "|  mar|\n",
      "|  apr|\n",
      "|  may|\n",
      "|  jun|\n",
      "|  jul|\n",
      "|  aug|\n",
      "|  sep|\n",
      "|  oct|\n",
      "|  nov|\n",
      "|  dec|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['month']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c652aa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'month'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a9c4d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('month', 'string'), ('spend', 'int')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2fac7fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------+\n",
      "|summary|month|  spend|\n",
      "+-------+-----+-------+\n",
      "|  count|   12|     12|\n",
      "|   mean| null|10000.0|\n",
      "| stddev| null|    0.0|\n",
      "|    min|  apr|  10000|\n",
      "|    max|  sep|  10000|\n",
      "+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a69dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding Columns in data frame\n",
    "df_pyspark=df_pyspark.withColumn('Experience After 2 year',df_pyspark['spend']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cacf99fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------------------+\n",
      "|month|spend|Experience After 2 year|\n",
      "+-----+-----+-----------------------+\n",
      "|  jan|10000|                  10002|\n",
      "|  feb|10000|                  10002|\n",
      "|  mar|10000|                  10002|\n",
      "|  apr|10000|                  10002|\n",
      "|  may|10000|                  10002|\n",
      "|  jun|10000|                  10002|\n",
      "|  jul|10000|                  10002|\n",
      "|  aug|10000|                  10002|\n",
      "|  sep|10000|                  10002|\n",
      "|  oct|10000|                  10002|\n",
      "|  nov|10000|                  10002|\n",
      "|  dec|10000|                  10002|\n",
      "+-----+-----+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6894fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop the columns\n",
    "df_pyspark=df_pyspark.drop('Experience After 2 year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f67270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|month|spend|\n",
      "+-----+-----+\n",
      "|  jan|10000|\n",
      "|  feb|10000|\n",
      "|  mar|10000|\n",
      "|  apr|10000|\n",
      "|  may|10000|\n",
      "|  jun|10000|\n",
      "|  jul|10000|\n",
      "|  aug|10000|\n",
      "|  sep|10000|\n",
      "|  oct|10000|\n",
      "|  nov|10000|\n",
      "|  dec|10000|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7639bbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Month|spend|\n",
      "+-----+-----+\n",
      "|  jan|10000|\n",
      "|  feb|10000|\n",
      "|  mar|10000|\n",
      "|  apr|10000|\n",
      "|  may|10000|\n",
      "|  jun|10000|\n",
      "|  jul|10000|\n",
      "|  aug|10000|\n",
      "|  sep|10000|\n",
      "|  oct|10000|\n",
      "|  nov|10000|\n",
      "|  dec|10000|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Rename the columns\n",
    "df_pyspark.withColumnRenamed('month','Month').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "641ef909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month', 'spend']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### find columns\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b90967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5017c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd785962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e56ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
